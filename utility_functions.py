import time,os,re
import numpy as np
from typing import List
from langchain.schema import Document
from llmUtils import get_databricks_chatmodel
from idmc_prompt import raw_prompt,follow_up_prompt
from databricks.vector_search.client import VectorSearchClient 
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser,StrOutputParser
from databricks.vector_search.reranker import DatabricksReranker 
from databricks_langchain import DatabricksEmbeddings


def check_index_status():
    try:
        index_name = os.getenv("DATABRICKS_IDMCLOGS_INDEX")
        client = VectorSearchClient(disable_notice=True)
        index = client.get_index(index_name=index_name)
        while not index.describe().get('status')['ready']:
            print("Waiting for index to be ONLINE...")
            time.sleep(5)
    except Exception as error:
        print(error)
        raise error
    
    return index
   

def convert_vector_search_to_documents(results) -> List[Document]:
    column_names = [col["name"] for col in results["manifest"]["columns"]]
    langchain_docs = []
    for item in results["result"]["data_array"]:
        metadata = {}
        for idx, field in enumerate(item[1:-1], start=1): 
            metadata[column_names[idx]] = field
        metadata["file_name"]
        doc = Document(
            page_content=metadata["page_content"],  
            metadata={"filename":metadata["file_name"]}
        )
        langchain_docs.append(doc)

    return langchain_docs

def get_contex_from_documents(index:str,user_query:str)-> str:

    try:
        results = index.similarity_search(
            query_text=user_query,
            columns=["id", "page_content","file_name"],
            num_results=15,
            query_type="hybrid",
            reranker=DatabricksReranker(columns_to_rerank=["page_content"])
            )
        similar_docs = convert_vector_search_to_documents(results)
        context = []
        pattern = r",|=|-->|\.{3}|\*|\.|^\s*$"
        for item in similar_docs:
            doc = {}
            filename = item.metadata["filename"]
            page_content = re.sub(pattern, "", item.page_content, flags=re.MULTILINE)
            doc["filename"] = filename
            doc["page_content"] = page_content
            context.append(doc)
        return context
    
    except Exception as error:
        return error

def get_response(context:str,user_query:str):
    try:
        model = get_databricks_chatmodel() 
        prompt = ChatPromptTemplate.from_template(template = raw_prompt)
        chain  = prompt | model | JsonOutputParser()
        response = chain.invoke({"query":user_query,"context":context})
        confidence_score = get_confindence_score(user_query,response["response"])
        follow_up_questions = get_follow_up_questions(user_query,response["response"]) 
        response["followup_questions"] = follow_up_questions 
        response["confidence_score"] = confidence_score
        return response

    except Exception as error:
        raise error
    
def get_confindence_score(question:str,response:str) -> int:
    """
    This function computes similarity between question and response generated by model
    """
   
    endpoint = os.getenv("DATABRICKS_EMBEDDING_ENDPOINT")
    embeddings = DatabricksEmbeddings(
        endpoint=endpoint
    )
    question_embedding = embeddings.embed_query(question)
    response_embedding = embeddings.embed_query(response)
    vec1 = np.array(question_embedding) / np.linalg.norm(question_embedding)
    vec2 = np.array(response_embedding) / np.linalg.norm(response_embedding)
    score = np.dot(vec1, vec2)
    return round((score + 1) / 2,2)


def get_follow_up_questions(question:str,response:str) -> List[str]:
    model = get_databricks_chatmodel() 
    prompt = ChatPromptTemplate.from_template(follow_up_prompt)
    chain = prompt | model | StrOutputParser()
    answer = chain.invoke({"question":question,"response":response})
    return [question.strip() for question in answer.split("|")]



# if __name__=='__main__':
#     query = "What all technical issues are you seeing? how to fix these?"
#     response="The technical issues seen in the provided context include row errors while fetching data from the database, SQL errors, fetch out of sequence errors, and adapter deinit errors. To fix these issues, it's recommended to check the database connections, SQL queries, and adapter configurations. Additionally, ensuring that the data is properly formatted and that there are no network issues can also help resolve these errors."
#     index = check_index_status()
#     context = get_contex_from_documents(index,query)
#     response = get_response(context,query)
#     print(response)
    # get_follow_up_questions(query,response)

    

    
    
